import pandas as pd
import numpy as np
data=pd.read_csv('golfstats1.csv')

X = data.drop('POINTS',1)   
X_data = X  
y = data['POINTS']
import matplotlib.pyplot as plt

# Apply Standard Scaler to dataset
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
data_scaled = sc.fit_transform(X)

# Apply PCA
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(data_scaled)
explainedvariance = pca.explained_variance_ratio_
# PCA Projection to 2 dimensions
principalDf = pd.DataFrame(data = X,
                           columns =['PC1','PC2'])

finalDf = pd.concat([principalDf, data[['POINTS']]],axis = 1)

# Plot PCs
plt.grid()
pts = plt.scatter(X_pca[:,0], X_pca[:,1],c = y)
           
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.colorbar(pts)

plt.title('2 Component PCA', fontsize=20)

#SVD(x) For testing linear dependency. if anything is close to zero, there is a linear dependency
# perform SVD and eliminate linearly dependent variables
u,s,vh = np.linalg.svd(X)

# Data looks good, should be able to run ANOVA now
from scipy.stats import f_oneway

#anova = f_oneway(y,data_scaled[:,0],data_scaled[:,1],data_scaled[:,2])
ans = f_oneway(y,data_scaled)
